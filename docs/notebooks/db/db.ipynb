{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Database\n",
    "\n",
    "The `DB()` object in the `dl_utils.db` module encapsulates functionality to organize project data and track data transformations as well as analysis. As the size and complexity of a project grows, use of the `DB()` object will ensure that:\n",
    "\n",
    "1. Project file paths are defined in a well-organized directory hierarchy\n",
    "2. Project metadata is serialized in a clear and standard format\n",
    "3. Code to perform data transformations and analysis are well-documented with clear input(s) and output(s)\n",
    "4. The entire data transformation pipeline can be applied easily to new cohorts\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* Initialization\n",
    "* Basic functionality\n",
    "* Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "The following lines of code prepare the requisite environment to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dl_utils.db import DB\n",
    "from dl_utils import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition this tutorial assumes that the `bet` example dataset has been downloaded in the `dl_utils/data` folder. If needed, the following lines of code will download the required data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set paths\n",
    "DAT_PATH = '../../../data'\n",
    "CSV_PATH = '{}/bet/csvs/db-all.csv.gz'.format(DAT_PATH)\n",
    "YML_PATH = '{}/bet/ymls/db-all.yml'.format(DAT_PATH)\n",
    "\n",
    "# --- Download data\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    datasets.download(name='bet', path=DAT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "All `DB()` object data including filenames and raw values are stored in a `*.csv` (or `*.csv.gz`) file. If necessary, all `DB()` object metadata such as filename directory roots, filename patterns or method definitions are stored in a `*.yml` file. Either file type may be passed directly into the `DB(...)` constructor to create a new object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating from a `*.csv` file\n",
    "\n",
    "All underlying raw `DB()` data is stored in a `*.csv` file. Each row in the `*.csv` file represents a single exam. Each column in the `*.csv` file may be one of three different types: sid, fnames, header.\n",
    "\n",
    "An example template `*.csv` file is shown here:\n",
    "\n",
    "```\n",
    "sid           fname-dat       fname-lbl       hemorrhage\n",
    "exam-id-000   /000/dat.hdf5   /000/lbl.hdf5   True\n",
    "exam-id-001   /001/dat.hdf5   /001/lbl.hdf5   False\n",
    "exam-id-002   /002/dat.hdf5   /002/lbl.hdf5   True\n",
    "...           ...             ...             ...\n",
    "```\n",
    "\n",
    "#### sid (required)\n",
    "\n",
    "Exactly one column in the `*.csv` file must be named `sid` and be populated with a **unique** study ID for each exam (row). The `sid` may be either numeric or alphanumeric in content.\n",
    "\n",
    "#### fnames (optional)\n",
    "\n",
    "If a project utilizes one or more serialized data volumes, the file paths should be maintained in columns specified with a `fname-` prefix (e.g. `fname-dat` and `fname-lbl` as above). Files may be listed using either complete or relative paths, or using a number of keywords. See `*.yml` configuration below for more information.\n",
    "\n",
    "#### header (optional)\n",
    "\n",
    "All other data for a project should be maintained in the remaining columns of the `*.csv` file (e.g. not `sid` and not prefixed with `fname-`). It is best practice to serialize a single value per column (e.g. either a numeric value or string), rather than storing multiple values as an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create from *.csv file\n",
    "db = DB(CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating from a `*.yml` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the raw `DB()` data stored in a `*.csv` file, various metadata that defines `DB()` behavior may also be specified in a corresponding `*.yml` file. \n",
    "\n",
    "An example template `*.yml` file is shown here:\n",
    "\n",
    "```yml\n",
    "files: \n",
    "  csv: /csvs/db-all.csv.gz\n",
    "  yml: /ymls/db-all.yml\n",
    "paths: \n",
    "  data: /path/to/data\n",
    "  code: /path/to/code\n",
    "sform: {}\n",
    "query: {}\n",
    "fdefs: []\n",
    "\n",
    "```\n",
    "\n",
    "#### files and paths (required)\n",
    "\n",
    "To facilitate transfer of code and data, relative paths are stored in the `files` variable, with path roots stored in the `pqths` variable. Thus:\n",
    "\n",
    "```python\n",
    "paths['code'] + files['csv'] # complete path to *.csv file\n",
    "paths['code'] + files['yml'] # complete path to *.yml file\n",
    "```\n",
    "\n",
    "Additionally, `paths['data']` represents the root directory for serialized data volumes.\n",
    "\n",
    "#### sform (optional)\n",
    "\n",
    "There are a two different methods to store files paths in the `*.csv` table (in columns prefixed with `fname-`). As above, the simplest method is to use the complete file path name. Alternatively, the `sform` dictionary may be set with key-values pairs where the key represents a column name and the value represents a Python string format pattern. The Python string format pattern may use one of three different keywords:\n",
    "\n",
    "* *root*: the data root directory (`paths['data'` as above)\n",
    "* *curr*: the current contents stored in the `*.csv` file\n",
    "* *sid*: the current exam study ID\n",
    "\n",
    "Consider the following examples (using the same template `*.csv` as above):\n",
    "\n",
    "##### Example 1\n",
    "\n",
    "```yml\n",
    "sform:\n",
    "  dat: '{root}/{curr}'\n",
    "  lbl: '{root}/{curr}`\n",
    "```\n",
    "\n",
    "... would be expanded to ...\n",
    "\n",
    "```\n",
    "sid           fname-dat                    fname-lbl       \n",
    "exam-id-000   /path/to/data/000/dat.hdf5   /path/to/data/000/lbl.hdf5\n",
    "exam-id-001   /path/to/data/001/dat.hdf5   /path/to/data/001/lbl.hdf5\n",
    "exam-id-002   /path/to/data/002/dat.hdf5   /path/to/data/002/lbl.hdf5\n",
    "...           ...             ...             ...\n",
    "```\n",
    "\n",
    "##### Example 2\n",
    "\n",
    "```yml\n",
    "sform:\n",
    "  dat: '{root}/{sid}/dat.hdf5'\n",
    "  lbl: '{root}/{sid}/lbl.hdf5`\n",
    "```\n",
    "\n",
    "... would be expanded to ...\n",
    "\n",
    "```\n",
    "sid           fname-dat                            fname-lbl       \n",
    "exam-id-000   /path/to/data/exam-id-000/dat.hdf5   /path/to/data/exam-id-000/lbl.hdf5\n",
    "exam-id-001   /path/to/data/exam-id-001/dat.hdf5   /path/to/data/exam-id-001/lbl.hdf5\n",
    "exam-id-002   /path/to/data/exam-id-002/dat.hdf5   /path/to/data/exam-id-002/lbl.hdf5\n",
    "...           ...             ...             ...\n",
    "```\n",
    "\n",
    "#### query (optional)\n",
    "\n",
    "As an alternative to manually identifying the relevant file paths, a simple query can configured to automatically find (and update) the requested data. The query dictinoary is defined simply using a root data directory and one or more matching suffix patterns. \n",
    "\n",
    "Consider the following example:\n",
    "\n",
    "```yml\n",
    "query:\n",
    "  root: /path/to/data\n",
    "  dat: dat.hdf5\n",
    "  lbl: lbl.hdf5\n",
    "```\n",
    "\n",
    "In this scenario:\n",
    "\n",
    "* column `fname-dat`: populated with results from `glob.glob('/path/to/data/**/dat.hdf5')`\n",
    "* column `fname-lbl`: populated with results from `glob.glob('/path/to/data/**/lbl.hdf5')`\n",
    "\n",
    "Note that corresponding `dat.hdf5` and `lbl.hdf5` files for the same exam are expected to be in the **same subdirectory**.\n",
    "\n",
    "#### fdefs (optional)\n",
    "\n",
    "See notes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create from *.yml file\n",
    "db = DB(YML_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon creating a `DB()` object, the underlying data structure is split into two separate `pandas` DataFrames, `db.fnames` and `db.header` (each DataFrame is an attribute of the main `DB()` object). The `db.fnames` DataFrame comprises of all `*.csv` columns prefixed with `fname-` (with the `fname-` prefix itself removed upon import); the `db.header` DataFrame contains all remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect fnames and header\n",
    "assert type(db.header) is pd.DataFrame\n",
    "assert type(db.fnames) is pd.DataFrame\n",
    "\n",
    "# --- Ensure all five exams are available\n",
    "assert db.fnames.shape[0] == 5\n",
    "assert db.header.shape[0] == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db.fnames\n",
    "\n",
    "See below for some basic functionality related to `db.fnames`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check to see if fnames exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tear Down"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
